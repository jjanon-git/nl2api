# P0.1: End-to-End Observability

**Priority:** P0 (Critical)
**Effort:** 1-2 weeks
**Status:** ðŸ”² Not Started

---

## Problem Statement

The NL2API system currently has only basic `logging` statements for debugging. There is no structured observability to:
- Trace requests end-to-end across components
- Identify latency bottlenecks in production
- Monitor error rates and failure patterns
- Track SLA compliance
- Debug accuracy issues with full context

---

## Goals

1. Add OpenTelemetry tracing with spans for each pipeline stage
2. Track latency, tokens, and accuracy metrics per request
3. Enable distributed tracing for future microservices architecture
4. Export to local (Jaeger) and cloud (Azure Monitor) backends

---

## Implementation Plan

### Phase 1: Core Instrumentation (3-5 days)

#### 1.1 Add OpenTelemetry Dependencies

**File:** `pyproject.toml`

```toml
[project.optional-dependencies]
observability = [
    "opentelemetry-api>=1.20.0",
    "opentelemetry-sdk>=1.20.0",
    "opentelemetry-exporter-otlp>=1.20.0",
    "opentelemetry-instrumentation-aiohttp>=0.41b0",
]
```

#### 1.2 Create Observability Module

**File:** `src/nl2api/observability/__init__.py`

```python
"""
Observability module for NL2API.

Provides:
- OpenTelemetry tracing
- Structured metrics
- Request context propagation
"""

from src.nl2api.observability.tracing import (
    init_tracing,
    get_tracer,
    trace_span,
)
from src.nl2api.observability.metrics import (
    RequestMetrics,
    emit_request_metrics,
)

__all__ = [
    "init_tracing",
    "get_tracer",
    "trace_span",
    "RequestMetrics",
    "emit_request_metrics",
]
```

#### 1.3 Create Tracing Module

**File:** `src/nl2api/observability/tracing.py`

```python
"""OpenTelemetry tracing configuration."""

from __future__ import annotations

import logging
from contextlib import contextmanager
from typing import Any, Generator

from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import Resource

logger = logging.getLogger(__name__)

_tracer: trace.Tracer | None = None


def init_tracing(
    service_name: str = "nl2api",
    otlp_endpoint: str | None = None,
    enable_console: bool = False,
) -> None:
    """
    Initialize OpenTelemetry tracing.

    Args:
        service_name: Name of the service for traces
        otlp_endpoint: OTLP collector endpoint (e.g., "localhost:4317")
        enable_console: Whether to also export to console
    """
    global _tracer

    resource = Resource.create({"service.name": service_name})
    provider = TracerProvider(resource=resource)

    if otlp_endpoint:
        otlp_exporter = OTLPSpanExporter(endpoint=otlp_endpoint, insecure=True)
        provider.add_span_processor(BatchSpanProcessor(otlp_exporter))
        logger.info(f"Tracing enabled: exporting to {otlp_endpoint}")

    if enable_console:
        from opentelemetry.sdk.trace.export import ConsoleSpanExporter
        provider.add_span_processor(BatchSpanProcessor(ConsoleSpanExporter()))

    trace.set_tracer_provider(provider)
    _tracer = trace.get_tracer(__name__)


def get_tracer() -> trace.Tracer:
    """Get the configured tracer."""
    global _tracer
    if _tracer is None:
        _tracer = trace.get_tracer(__name__)
    return _tracer


@contextmanager
def trace_span(
    name: str,
    attributes: dict[str, Any] | None = None,
) -> Generator[trace.Span, None, None]:
    """
    Context manager for creating a traced span.

    Args:
        name: Span name (e.g., "entity_resolution", "routing")
        attributes: Optional span attributes

    Yields:
        The active span
    """
    tracer = get_tracer()
    with tracer.start_as_current_span(name) as span:
        if attributes:
            for key, value in attributes.items():
                span.set_attribute(key, value)
        yield span
```

### Phase 2: Orchestrator Instrumentation (3-5 days)

#### 2.1 Instrument Orchestrator

**File:** `src/nl2api/orchestrator.py` (modifications)

Add tracing spans to each step in `process()`:

```python
from src.nl2api.observability import trace_span, RequestMetrics, emit_request_metrics

async def process(self, query: str, session_id: str | None = None, ...) -> NL2APIResponse:
    """Process with full tracing."""

    with trace_span("nl2api.process", {"query_length": len(query)}) as root_span:
        metrics = RequestMetrics(query=query, session_id=session_id)

        try:
            # Step 1: Session management
            with trace_span("session.get_or_create") as span:
                session = await self._conversation_manager.get_or_create_session(...)
                span.set_attribute("session.id", str(session.id))
                span.set_attribute("session.turns", session.total_turns)

            # Step 2: Query expansion
            with trace_span("query.expansion") as span:
                if session.total_turns > 0:
                    expansion_result = self._conversation_manager.expand_query(...)
                    span.set_attribute("query.expanded", expansion_result.was_expanded)
                    if expansion_result.was_expanded:
                        span.set_attribute("query.expanded_length", len(expansion_result.expanded_query))

            # Step 3: Entity resolution
            with trace_span("entity.resolution") as span:
                resolved_entities = await self._entity_resolver.resolve(effective_query)
                span.set_attribute("entities.count", len(resolved_entities))
                span.set_attribute("entities.names", list(resolved_entities.keys()))
                metrics.entities_resolved = len(resolved_entities)

            # Step 4: Routing
            with trace_span("routing") as span:
                domain, confidence = await self._classify_query(effective_query)
                span.set_attribute("routing.domain", domain)
                span.set_attribute("routing.confidence", confidence)
                span.set_attribute("routing.cached", ...)  # from router result
                metrics.routing_domain = domain
                metrics.routing_confidence = confidence

            # Step 5: Context retrieval
            with trace_span("context.retrieval") as span:
                field_codes, query_examples = await self._retrieve_context(...)
                span.set_attribute("context.field_codes", len(field_codes))
                span.set_attribute("context.examples", len(query_examples))
                span.set_attribute("context.mode", self._context_mode)

            # Step 6: Agent processing
            with trace_span("agent.process", {"agent": domain}) as span:
                result = await agent.process(context)
                span.set_attribute("agent.used_llm", result.used_llm)
                span.set_attribute("agent.tool_calls", len(result.tool_calls))
                span.set_attribute("agent.tokens", result.tokens_used or 0)
                metrics.agent_used_llm = result.used_llm
                metrics.tokens_used = result.tokens_used

            # Emit metrics
            metrics.success = True
            metrics.tool_calls = len(result.tool_calls)

        except Exception as e:
            root_span.record_exception(e)
            metrics.success = False
            metrics.error = str(e)
            raise

        finally:
            metrics.latency_ms = int((time.perf_counter() - start_time) * 1000)
            emit_request_metrics(metrics)
            root_span.set_attribute("total_latency_ms", metrics.latency_ms)
```

#### 2.2 Instrument Router

**File:** `src/nl2api/routing/llm_router.py` (modifications)

```python
from src.nl2api.observability import trace_span

async def route(self, query: str, context: dict | None = None) -> RouterResult:
    with trace_span("router.route") as span:
        # Check cache
        with trace_span("router.cache_lookup") as cache_span:
            if self._cache:
                cached = await self._cache.get(query)
                cache_span.set_attribute("cache.hit", cached is not None)
                if cached:
                    return cached

        # LLM routing
        with trace_span("router.llm_call") as llm_span:
            response = await self._llm.complete(...)
            llm_span.set_attribute("llm.model", self._llm.model_name)
            llm_span.set_attribute("llm.tokens", response.usage.total_tokens if response.usage else 0)
```

### Phase 3: Metrics Module (2-3 days)

#### 3.1 Create Metrics Data Model

**File:** `src/nl2api/observability/metrics.py`

```python
"""Request metrics collection and emission."""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass, field, asdict
from datetime import datetime, UTC
from typing import Any

logger = logging.getLogger(__name__)


@dataclass
class RequestMetrics:
    """Metrics collected for each request."""

    # Request identifiers
    request_id: str = field(default_factory=lambda: str(uuid4()))
    session_id: str | None = None
    timestamp: str = field(default_factory=lambda: datetime.now(UTC).isoformat())

    # Input
    query: str = ""
    query_length: int = 0

    # Entity resolution
    entities_resolved: int = 0
    entity_names: list[str] = field(default_factory=list)

    # Routing
    routing_domain: str = ""
    routing_confidence: float = 0.0
    routing_cached: bool = False
    routing_latency_ms: int = 0
    routing_model: str | None = None

    # Context
    context_mode: str = "local"
    field_codes_retrieved: int = 0
    examples_retrieved: int = 0

    # Agent
    agent_used_llm: bool = False
    agent_rule_matched: str | None = None

    # Output
    tool_calls: int = 0
    tool_names: list[str] = field(default_factory=list)

    # Performance
    latency_ms: int = 0
    tokens_used: int = 0

    # Status
    success: bool = True
    error: str | None = None
    needs_clarification: bool = False

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for logging."""
        return asdict(self)

    def to_json(self) -> str:
        """Convert to JSON string for structured logging."""
        return json.dumps(self.to_dict())


def emit_request_metrics(metrics: RequestMetrics) -> None:
    """
    Emit request metrics to configured backends.

    Currently logs as structured JSON. Can be extended to:
    - Azure Monitor
    - Prometheus
    - Custom analytics pipeline
    """
    # Structured JSON log for analytics
    logger.info(
        "request_metrics",
        extra={"metrics": metrics.to_dict()},
    )

    # Also log summary at INFO level for quick debugging
    logger.info(
        f"Request completed: domain={metrics.routing_domain} "
        f"confidence={metrics.routing_confidence:.2f} "
        f"cached={metrics.routing_cached} "
        f"llm={metrics.agent_used_llm} "
        f"tools={metrics.tool_calls} "
        f"latency={metrics.latency_ms}ms "
        f"tokens={metrics.tokens_used}"
    )
```

### Phase 4: Configuration (1-2 days)

#### 4.1 Add Observability Config

**File:** `src/nl2api/config.py` (additions)

```python
class NL2APIConfig(BaseSettings):
    # ... existing config ...

    # Observability settings
    tracing_enabled: bool = Field(default=False, description="Enable OpenTelemetry tracing")
    tracing_otlp_endpoint: str | None = Field(default=None, description="OTLP collector endpoint")
    tracing_console_export: bool = Field(default=False, description="Export traces to console")

    metrics_enabled: bool = Field(default=True, description="Enable request metrics")
    metrics_log_level: str = Field(default="INFO", description="Log level for metrics")
```

---

## Files to Create

| File | Purpose |
|------|---------|
| `src/nl2api/observability/__init__.py` | Module exports |
| `src/nl2api/observability/tracing.py` | OpenTelemetry tracing setup |
| `src/nl2api/observability/metrics.py` | Request metrics collection |
| `tests/unit/nl2api/observability/test_tracing.py` | Tracing tests |
| `tests/unit/nl2api/observability/test_metrics.py` | Metrics tests |

## Files to Modify

| File | Changes |
|------|---------|
| `src/nl2api/orchestrator.py` | Add trace spans and metrics collection |
| `src/nl2api/routing/llm_router.py` | Add trace spans for routing |
| `src/nl2api/routing/cache.py` | Add trace spans for cache operations |
| `src/nl2api/config.py` | Add observability configuration |
| `pyproject.toml` | Add opentelemetry dependencies |

---

## Testing Plan

1. **Unit Tests**
   - Test trace span creation and attributes
   - Test metrics data model
   - Test metrics emission

2. **Integration Tests**
   - Verify traces are exported to Jaeger
   - Verify metrics are logged correctly
   - Test with tracing disabled (no-op)

3. **Manual Verification**
   - Run with Jaeger locally: `docker run -p 16686:16686 -p 4317:4317 jaegertracing/all-in-one`
   - Submit test queries
   - Verify trace visualization in Jaeger UI

---

## Success Criteria

- [ ] All orchestrator steps have trace spans
- [ ] Request metrics are emitted for every request
- [ ] Traces can be viewed in Jaeger
- [ ] No performance regression (< 5ms overhead)
- [ ] 90%+ test coverage for observability module

---

## Rollback Plan

Observability is opt-in via configuration. If issues arise:
1. Set `tracing_enabled=false` in config
2. Tracing code becomes no-op
3. No impact on core functionality
