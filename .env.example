# NL2API Configuration
# Copy this to .env and fill in your values
#
# SECURITY: Never commit .env to git. Only .env.example should be tracked.

# =============================================================================
# Docker Infrastructure Credentials
# =============================================================================
# These are used by docker-compose.yml. Change from defaults for production!

# PostgreSQL
POSTGRES_USER=nl2api
POSTGRES_PASSWORD=change_me_in_production
POSTGRES_DB=nl2api

# Redis (leave empty to disable auth in development)
REDIS_PASSWORD=
# If using Redis password, also set the full URL for MCP server:
# ENTITY_MCP_REDIS_URL=redis://:your_password@redis:6379/0

# Grafana
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=change_me_in_production

# =============================================================================
# Application Configuration
# =============================================================================

# LLM Provider: "claude" or "openai"
NL2API_LLM_PROVIDER=claude

# Claude (Anthropic) - required if using claude provider
NL2API_ANTHROPIC_API_KEY=sk-ant-api03-...

# OpenAI - required if using openai provider
# NL2API_OPENAI_API_KEY=sk-...

# Model override (optional)
# NL2API_LLM_MODEL=claude-sonnet-4-20250514

# Azure OpenAI (if using azure_openai provider)
# NL2API_AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# NL2API_AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Database (for RAG and batch storage)
# NL2API_POSTGRES_URL=postgresql://nl2api:nl2api@localhost:5432/nl2api

# =============================================================================
# Phase 5: Scale & Production Settings
# =============================================================================

# Redis Cache (optional, for distributed caching)
# NL2API_REDIS_ENABLED=true
# NL2API_REDIS_URL=redis://localhost:6379/0
# NL2API_REDIS_DEFAULT_TTL_SECONDS=3600
# NL2API_REDIS_ENTITY_CACHE_TTL_SECONDS=86400
# NL2API_REDIS_RAG_CACHE_TTL_SECONDS=3600

# Entity Resolution - External Service
# Circuit breaker protects against cascading failures
# NL2API_ENTITY_RESOLUTION_API_ENDPOINT=https://your-entity-service.com
# NL2API_ENTITY_RESOLUTION_API_KEY=your-api-key
# NL2API_ENTITY_RESOLUTION_TIMEOUT_SECONDS=5.0
# NL2API_ENTITY_RESOLUTION_CIRCUIT_FAILURE_THRESHOLD=5
# NL2API_ENTITY_RESOLUTION_CIRCUIT_RECOVERY_SECONDS=30.0
# NL2API_ENTITY_RESOLUTION_RETRY_MAX_ATTEMPTS=3

# Embedding Rate Limits (for OpenAI embeddings)
# NL2API_EMBEDDING_MAX_CONCURRENT=5
# NL2API_EMBEDDING_REQUESTS_PER_MINUTE=3000

# RAG Indexing (for bulk operations)
# NL2API_RAG_INDEXING_BATCH_SIZE=100
# NL2API_RAG_INDEXING_USE_BULK_INSERT=true
# NL2API_RAG_INDEXING_CHECKPOINT_ENABLED=true

# =============================================================================
# Telemetry & Observability (OpenTelemetry)
# =============================================================================

# Enable OpenTelemetry instrumentation
# NL2API_TELEMETRY_ENABLED=true

# OTLP collector endpoint (run `docker compose up -d` for local stack)
# NL2API_TELEMETRY_OTLP_ENDPOINT=http://localhost:4317

# Service identification
# NL2API_TELEMETRY_SERVICE_NAME=nl2api

# Feature toggles
# NL2API_TELEMETRY_TRACING_ENABLED=true
# NL2API_TELEMETRY_METRICS_ENABLED=true
# NL2API_TELEMETRY_EXPORT_INTERVAL_MS=10000

# Metrics emission backends
# NL2API_METRICS_LOG_ENABLED=true
# NL2API_METRICS_FILE_PATH=/var/log/nl2api/metrics.jsonl
# NL2API_METRICS_OTEL_ENABLED=true

# Observability Stack URLs (for reference, after docker compose up)
# Grafana:     http://localhost:3000 (admin/admin)
# Prometheus:  http://localhost:9090
# Jaeger:      http://localhost:16686
